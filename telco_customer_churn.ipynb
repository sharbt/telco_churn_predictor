{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc774c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Telco churn training script with data preparation, feature engineering,\n",
    "two-model training (LogisticRegression, RandomForest), hyperparameter tuning,\n",
    "evaluation, and best-model export.\n",
    "\n",
    "Expected CSV columns:\n",
    "customerID, gender, SeniorCitizen, Partner, Dependents, tenure, PhoneService,\n",
    "MultipleLines, InternetService, Contract, PaymentMethod, MonthlyCharges, TotalCharges, Churn\n",
    "\"\"\"\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             classification_report, confusion_matrix, roc_auc_score)\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def load_and_clean(path):\n",
    "    df = pd.read_csv(path)\n",
    "    expected = [\"customerID\",\"gender\",\"SeniorCitizen\",\"Partner\",\"Dependents\",\"tenure\",\n",
    "                \"PhoneService\",\"MultipleLines\",\"InternetService\",\"Contract\",\"PaymentMethod\",\n",
    "                \"MonthlyCharges\",\"TotalCharges\",\"Churn\"]\n",
    "    missing = [c for c in expected if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in CSV: {missing}\")\n",
    "\n",
    "    # Clean whitespace\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "    # Coerce numeric\n",
    "    df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"].replace(\"\", np.nan), errors=\"coerce\")\n",
    "    df[\"SeniorCitizen\"] = pd.to_numeric(df[\"SeniorCitizen\"], errors=\"coerce\")\n",
    "    df[\"tenure\"] = pd.to_numeric(df[\"tenure\"], errors=\"coerce\")\n",
    "    df[\"MonthlyCharges\"] = pd.to_numeric(df[\"MonthlyCharges\"], errors=\"coerce\")\n",
    "\n",
    "    # Drop rows with target missing\n",
    "    df = df.dropna(subset=[\"Churn\"])\n",
    "\n",
    "    # Drop extremely sparse rows if many missing\n",
    "    thresh = int(df.shape[1] * 0.6)\n",
    "    df = df.dropna(thresh=thresh)\n",
    "\n",
    "    return df\n",
    "\n",
    "def cap_outliers_iqr(df, cols, factor=1.5):\n",
    "    # In-place cap using IQR\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            continue\n",
    "        series = df[c].dropna()\n",
    "        if series.empty:\n",
    "            continue\n",
    "        q1 = series.quantile(0.25)\n",
    "        q3 = series.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        low = q1 - factor * iqr\n",
    "        high = q3 + factor * iqr\n",
    "        df[c] = np.where(df[c] < low, low, df[c])\n",
    "        df[c] = np.where(df[c] > high, high, df[c])\n",
    "    return df\n",
    "\n",
    "def build_preprocessor(numeric_features, categorical_features):\n",
    "    # Numeric: median impute + robust scaling (resistant to outliers)\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", RobustScaler())\n",
    "    ])\n",
    "\n",
    "    # Categorical: most frequent impute + one-hot\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ], remainder=\"drop\")\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "def main(args):\n",
    "    df = load_and_clean(args.data)\n",
    "\n",
    "    # Map target\n",
    "    df[\"Churn\"] = df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "    if df[\"Churn\"].isnull().any():\n",
    "        df = df.dropna(subset=[\"Churn\"])\n",
    "\n",
    "    # Drop id\n",
    "    X = df.drop(columns=[\"customerID\", \"Churn\"])\n",
    "    y = df[\"Churn\"].astype(int)\n",
    "\n",
    "    # Numeric / categorical lists\n",
    "    numeric_features = [\"SeniorCitizen\", \"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "    categorical_features = [c for c in X.columns if c not in numeric_features]\n",
    "\n",
    "    # Handle outliers before pipeline (cap using IQR)\n",
    "    X = cap_outliers_iqr(X.copy(), numeric_features, factor=1.5)\n",
    "\n",
    "    preprocessor = build_preprocessor(numeric_features, categorical_features)\n",
    "\n",
    "    # Pipeline includes optional dimensionality step (SelectKBest or PCA) and classifier placeholder\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"dimred\", \"passthrough\"),      # will be set in GridSearchCV\n",
    "        (\"clf\", LogisticRegression(max_iter=1000, solver=\"lbfgs\"))\n",
    "    ])\n",
    "\n",
    "    param_grid = [\n",
    "        # Logistic regression branch\n",
    "        {\n",
    "            \"dimred\": [\"passthrough\", SelectKBest(score_func=f_classif)],\n",
    "            \"dimred__k\": [10, 15, \"all\"],\n",
    "            \"clf\": [LogisticRegression(max_iter=2000, solver=\"liblinear\")],\n",
    "            \"clf__C\": [0.01, 0.1, 1.0, 10.0],\n",
    "            \"clf__penalty\": [\"l2\"]\n",
    "        },\n",
    "        # Random forest branch\n",
    "        {\n",
    "            \"dimred\": [\"passthrough\", SelectKBest(score_func=f_classif), PCA()],\n",
    "            \"dimred__k\": [10, 15, \"all\"],\n",
    "            \"dimred__n_components\": [5, 10],  # only used if PCA selected; GridSearch ignores when not applicable\n",
    "            \"clf\": [RandomForestClassifier(random_state=42, n_jobs=-1)],\n",
    "            \"clf__n_estimators\": [100, 250],\n",
    "            \"clf__max_depth\": [None, 10, 20]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.20, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # Grid search\n",
    "    gs = GridSearchCV(pipe, param_grid, cv=StratifiedKFold(n_splits=5), scoring=\"f1\",\n",
    "                      n_jobs=-1, verbose=1, refit=True)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    best = gs.best_estimator_\n",
    "    print(f\"Best params: {gs.best_params_}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    y_pred = best.predict(X_test)\n",
    "    y_proba = best.predict_proba(X_test)[:, 1] if hasattr(best, \"predict_proba\") else None\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_test, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_test, y_pred, zero_division=0),\n",
    "        \"roc_auc\": roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    }\n",
    "\n",
    "    print(\"Evaluation on test set:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k}: {v:.4f}\" if v is not None else f\"  {k}: None\")\n",
    "    print(\"\\nClassification report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"No\", \"Yes\"]))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Save best model\n",
    "    model_out = args.model_out or \"best_telco_churn_model.joblib\"\n",
    "    joblib.dump(best, model_out)\n",
    "    print(f\"Saved best model to: {model_out}\")\n",
    "\n",
    "    # Short fairness/bias reflection\n",
    "    print(\"\\nFairness notes:\")\n",
    "    print(\"- Check model performance across sensitive groups (e.g., gender, SeniorCitizen).\")\n",
    "    print(\"- Compare precision/recall for subgroups; consider reweighting or separate thresholds if disparities exist.\")\n",
    "    print(\"- Document dataset collection and known limitations before deployment.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = argparse.ArgumentParser(description=\"Train telco churn models with preprocessing and tuning\")\n",
    "    p.add_argument(\"--data\", required=True, help=\"Path to telco CSV file\")\n",
    "    p.add_argument(\"--model-out\", required=False, help=\"Output path for saved model (joblib)\")\n",
    "    args = p.parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Train and evaluate a churn model for a telecom dataset.\n",
    "\n",
    "Expected CSV columns:\n",
    "customerID, gender, SeniorCitizen, Partner, Dependents, tenure, PhoneService,\n",
    "MultipleLines, InternetService, Contract, PaymentMethod, MonthlyCharges, TotalCharges, Churn\n",
    "\n",
    "Usage:\n",
    "python telco_churn_model.py --data telco_churn.csv\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import joblib\n",
    "import sys\n",
    "\n",
    "def load_and_clean(path):\n",
    "    df = pd.read_csv(path)\n",
    "    expected = [\"customerID\",\"gender\",\"SeniorCitizen\",\"Partner\",\"Dependents\",\"tenure\",\n",
    "                \"PhoneService\",\"MultipleLines\",\"InternetService\",\"Contract\",\"PaymentMethod\",\n",
    "                \"MonthlyCharges\",\"TotalCharges\",\"Churn\"]\n",
    "    missing = [c for c in expected if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in CSV: {missing}\")\n",
    "\n",
    "    # Coerce TotalCharges to numeric (some datasets have blanks)\n",
    "    df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "    # Optionally drop rows with missing target\n",
    "    df = df.dropna(subset=[\"Churn\"])\n",
    "\n",
    "    # Some datasets have spaces in categorical values; strip strings\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].str.strip()\n",
    "\n",
    "    return df\n",
    "\n",
    "def build_pipeline(numeric_features, categorical_features):\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "    pipe = Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                           (\"clf\", clf)])\n",
    "    return pipe\n",
    "\n",
    "def main(args):\n",
    "    df = load_and_clean(args.data)\n",
    "\n",
    "    # Drop identifier\n",
    "    X = df.drop(columns=[\"customerID\", \"Churn\"])\n",
    "    y = df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})  # map target\n",
    "\n",
    "    # Ensure numeric columns are numeric\n",
    "    # 'SeniorCitizen' sometimes stored as int or object; coerce to numeric\n",
    "    X[\"SeniorCitizen\"] = pd.to_numeric(X[\"SeniorCitizen\"], errors=\"coerce\")\n",
    "\n",
    "    numeric_features = [\"SeniorCitizen\", \"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "    categorical_features = [c for c in X.columns if c not in numeric_features]\n",
    "\n",
    "    # Build pipeline\n",
    "    pipe = build_pipeline(numeric_features, categorical_features)\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # Fit\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    y_proba = pipe.predict_proba(X_test)[:, 1] if hasattr(pipe.named_steps['clf'], \"predict_proba\") else None\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    if y_proba is not None:\n",
    "        print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "    print(\"Classification report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=[\"No\", \"Yes\"]))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Save model\n",
    "    model_out = args.model_out or \"telco_churn_model.joblib\"\n",
    "    joblib.dump(pipe, model_out)\n",
    "    print(f\"Saved trained pipeline to: {model_out}\")\n",
    "\n",
    "    # Optional: show top feature importances (best-effort)\n",
    "    try:\n",
    "        clf = pipe.named_steps[\"clf\"]\n",
    "        pre = pipe.named_steps[\"preprocessor\"]\n",
    "        # get feature names after one-hot\n",
    "        ohe = pre.named_transformers_[\"cat\"].named_steps[\"onehot\"]\n",
    "        cat_cols = pre.transformers_[1][2]  # categorical feature names list\n",
    "        # feature names for ohe\n",
    "        ohe_names = list(ohe.get_feature_names_out(cat_cols))\n",
    "        feature_names = numeric_features + ohe_names\n",
    "        importances = clf.feature_importances_\n",
    "        top_idx = np.argsort(importances)[::-1][:10]\n",
    "        print(\"Top feature importances:\")\n",
    "        for i in top_idx:\n",
    "            print(f\" {feature_names[i]}: {importances[i]:.4f}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # If user asked to show example prediction, predict for first test row\n",
    "    example = X_test.iloc[[0]]\n",
    "    proba = pipe.predict_proba(example)[0][1] if hasattr(pipe.named_steps['clf'], \"predict_proba\") else None\n",
    "    print(\"\\nExample customer (first test row):\")\n",
    "    print(example.to_dict(orient=\"records\")[0])\n",
    "    if proba is not None:\n",
    "        print(f\"Predicted churn probability: {proba:.3f}\")\n",
    "    print(\"Predicted class:\", \"Yes\" if pipe.predict(example)[0] == 1 else \"No\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = argparse.ArgumentParser(description=\"Train a telco churn model\")\n",
    "    p.add_argument(\"--data\", required=True, help=\"Path to telco CSV file\")\n",
    "    p.add_argument(\"--model-out\", required=False, help=\"Output path for saved model (joblib)\")\n",
    "    args = p.parse_args()\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
